{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsnetmimic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icapucap/capsnet/blob/master/capsnetmimic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQHvbmEyfRQO",
        "colab_type": "text"
      },
      "source": [
        "# **CapsNet - Capsule Networks**\n",
        "\n",
        "##### This is an implementation of the paper *Sabour et. al*. - [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829) as part of the course IT 290 Seminar course.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Introduction**\n",
        "\n",
        "### **Problem with CNNs:**\n",
        "\n",
        "##### CNNs perform exceptionally great when they are classifying images which are very close to the data set. If the images have rotation, tilt or any other different orientation then CNNs have poor performance. This problem was solved by adding different variations of the same image during training. In CNN each layer understands an image at a much more granular level. We use pooling after each layer to make it compute in reasonable time frames. But in essence it also loses out the positional data.\n",
        "\n",
        "##### Pooling helps in creating the positional invariance. Otherwise CNNs would fit only for images or data which are very close to the training set. This invariance also leads to triggering false positive for images which have the components of a ship but not in the correct order.\n",
        "\n",
        "### **Capsules: Motivation and advantages**\n",
        "\n",
        "##### A Capsule is a nested set of neural layers. So in a regular neural network you keep on adding more layers. In CapsNet you would add more layers inside a single layer. A capsule outputs a vector to represent the existence of the entity. The orientation of the vector represents the properties of the entity. The vector is sent to all possible parents in the neural network. For each possible parent a capsule can find a prediction vector. Prediction vector is calculated based on multiplying it’s own weight and a weight matrix. Whichever parent has the largest scalar prediction vector product, increases the capsule bond. Rest of the parents decrease their bond. This routing by agreement method is superior than the current mechanism like max-pooling. Max pooling routes based on the strongest feature detected in the lower layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wz2lV0tvroq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WCJqnt9urgk",
        "colab_type": "code",
        "outputId": "c243fc04-6fa1-4ca5-fa4b-41f59133c366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b5b8009d9ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU034b44vqAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps1_n_maps = 32\n",
        "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
        "caps1_n_dims = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrF6kBszhvd_",
        "colab_type": "text"
      },
      "source": [
        "### **The next cell defines the parameters for the 2 convolutional layers that will be used to build the CapsNet**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BhU2sYBv2VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1_params = {\n",
        "    \"filters\": 256,\n",
        "    \"kernel_size\": 9,\n",
        "    \"strides\": 1,\n",
        "    \"padding\": \"valid\",\n",
        "    \"activation\": tf.nn.relu,\n",
        "}\n",
        "\n",
        "conv2_params = {\n",
        "    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
        "    \"kernel_size\": 9,\n",
        "    \"strides\": 2,\n",
        "    \"padding\": \"valid\",\n",
        "    \"activation\": tf.nn.relu\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8v6vsO0v-sO",
        "colab_type": "code",
        "outputId": "fe6e6638-64f6-43b1-f41b-031c09f2b5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n",
        "conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-3a2df923b7cc>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt5DCwc7wAvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
        "                       name=\"caps1_raw\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y89yvWG5iH-Q",
        "colab_type": "text"
      },
      "source": [
        "# **Squashing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J506x_L2iPjJ",
        "colab_type": "text"
      },
      "source": [
        "##### Squashing is a non-linearity operation. So instead of adding squashing to each layer like how one would do in a convolutional network, one would add the squashing to a nested set of layers. So the squashing function gets applied to the vector output of each capsule.\n",
        "\n",
        "##### The paper introduces a new squashing operation.\n",
        "\n",
        "![alt text](https://pechyonkin.me/images/201711-capsules-2/squash.png)\n",
        "\n",
        "##### ReLU or similar non linearity functions work well with single neurons. But the paper found that this squashing function works best with capsules. This tries to squash the length of output vector of a capsule. It squashes to 0 if it is a small vector and tries to limit the output vector to 1 if the vector is long. The dynamic routing adds some extra computation cost. But it definitely gives added advantage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aERjA5rBwJQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
        "    with tf.name_scope(name, default_name=\"squash\"):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
        "                                     keep_dims=True)\n",
        "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
        "        squash_factor = squared_norm / (1. + squared_norm)  # Squashing\n",
        "        unit_vector = s / safe_norm                         # Unit scaling\n",
        "        return squash_factor * unit_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqI5m5PTwMEE",
        "colab_type": "code",
        "outputId": "d8056463-1ba2-4045-964f-f8640af2c29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "caps1_output = squash(caps1_raw, name=\"caps1_output\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-8037c6cbfef1>:4: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edWU-N9swOgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_n_caps = 10\n",
        "caps2_n_dims = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOrQret9wZJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_sigma = 0.1\n",
        "\n",
        "W_init = tf.random_normal(\n",
        "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
        "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
        "W = tf.Variable(W_init, name=\"W\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3CM0nYHwcAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = tf.shape(X)[0]\n",
        "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcxeDsCnweH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
        "                                       name=\"caps1_output_expanded\")\n",
        "caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
        "                                   name=\"caps1_output_tile\")\n",
        "caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
        "                             name=\"caps1_output_tiled\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S_QjSJZwil1",
        "colab_type": "code",
        "outputId": "36ead92b-b1d4-4a18-882c-b561b0402a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W_tiled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'W_tiled:0' shape=(?, 1152, 10, 16, 8) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNXew0rewlOd",
        "colab_type": "code",
        "outputId": "4f2b2ad4-9017-4739-b66e-d20b83061d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps1_output_tiled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps1_output_tiled:0' shape=(?, 1152, 10, 8, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k2Vqcy8wnbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
        "                            name=\"caps2_predicted\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSdOpR3Iwqfn",
        "colab_type": "code",
        "outputId": "409bd8c9-dce4-4f13-a4a5-9fe5ddff0b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_predicted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqOxYXMswsRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
        "                       dtype=np.float32, name=\"raw_weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJIcCuomkdf8",
        "colab_type": "text"
      },
      "source": [
        "# **Dynamic routing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzr8gqEPmguR",
        "colab_type": "text"
      },
      "source": [
        "##### A capsule i in a lower-level layer needs to decide how to send its output vector to higher-level capsules j. It makes this decision by changing scalar weight C(i,j) that will multiply its output vector and then be treated as input to a higher-level capsule. \n",
        "\n",
        "#### **\"Lower level capsule will send its input to the higher level capsule that “agrees” with its input. This is the essence of the dynamic routing algorithm.\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGch_gpzkj10",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/2548/1*ukE9EQ6Yd6IPIu1cLJWSEQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9x9v3TWlCs_",
        "colab_type": "text"
      },
      "source": [
        "*   This procedure takes all capsules in a lower level l and their outputs u^, as well as the number of routing iterations r. The algorithm will produce the output of a higher level capsule vj. Essentially, this algorithm tells us how to calculate forward pass of the network.\n",
        "\n",
        "*  Step in line 4 calculates the value of vector ci which is all routing weights for a lower level capsule i. This is done for all lower level capsules. Softmax enforces probabilistic nature of coefficients cij that I described above.\n",
        "\n",
        "* At the first iteration, the value of all coefficients cij will be equal and represents the state of maximum confusion and uncertainty: lower level capsules have no idea which higher level capsules will best fit their output. \n",
        "\n",
        "* Line 5 is where we look at higher level capsules. This step calculates a linear combination of input vectors, weighted by routing coefficients cij, determined in the previous step. Intuitively, this means scaling down input vectors and adding them together, which produces output vector sj. This is done for all higher level capsules.\n",
        "\n",
        "* Next, in line 6 vectors from last step are passed through the squash nonlinearity, that makes sure the direction of the vector is preserved, but its length is enforced to be no more than 1. This step produces the output vector vj for all higher level capsules.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg4rD-5XwvGG",
        "colab_type": "code",
        "outputId": "ac586701-48a8-4ec2-9555-06781ec9aa34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-86a489ae595f>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwkyp2WBwxl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n",
        "                                   name=\"weighted_predictions\")\n",
        "weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n",
        "                             name=\"weighted_sum\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYtzoY3Fw0Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_output_round_1 = squash(weighted_sum, axis=-2,\n",
        "                              name=\"caps2_output_round_1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWx7s2Ydw26Q",
        "colab_type": "code",
        "outputId": "16f508d2-f18c-4fef-9cae-19ba83795c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_output_round_1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w30lMc9Jw4iF",
        "colab_type": "code",
        "outputId": "40f0062a-06d1-4bb7-ccc5-6e2d9047222f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_predicted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_predicted:0' shape=(?, 1152, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d4f6ogRw7J1",
        "colab_type": "code",
        "outputId": "6c6977a7-0e2e-4cf9-fdf2-795281cb9e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_output_round_1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_1/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa1FKa4Aw9uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_output_round_1_tiled = tf.tile(\n",
        "    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n",
        "    name=\"caps2_output_round_1_tiled\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F09Fh-6txCAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n",
        "                      transpose_a=True, name=\"agreement\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYzMSM_4xEln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_weights_round_2 = tf.add(raw_weights, agreement,\n",
        "                             name=\"raw_weights_round_2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBn41CA-xGws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n",
        "                                        dim=2,\n",
        "                                        name=\"routing_weights_round_2\")\n",
        "weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n",
        "                                           caps2_predicted,\n",
        "                                           name=\"weighted_predictions_round_2\")\n",
        "weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n",
        "                                     axis=1, keep_dims=True,\n",
        "                                     name=\"weighted_sum_round_2\")\n",
        "caps2_output_round_2 = squash(weighted_sum_round_2,\n",
        "                              axis=-2,\n",
        "                              name=\"caps2_output_round_2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6PUPsKaxKJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_output = caps2_output_round_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLsgioMSxMIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
        "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
        "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
        "                                     keep_dims=keep_dims)\n",
        "        return tf.sqrt(squared_norm + epsilon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXR2Zrj7xQWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce7G8POwxSxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6QZZcfkxVZ0",
        "colab_type": "code",
        "outputId": "eda59039-4b2d-4cb8-fbb7-3be3f5bbdede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_proba_argmax"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'y_proba_1:0' shape=(?, 1, 1) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu3RlTY5xW5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LprqNSgaxY_X",
        "colab_type": "code",
        "outputId": "c233bcb0-a7a5-4e17-bc0d-5a77024483a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBAo_Do6xal-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PShGochZxeWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_plus = 0.9\n",
        "m_minus = 0.1\n",
        "lambda_ = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI_RVtFFxgwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "240KuQ1nxjPP",
        "colab_type": "code",
        "outputId": "3d46f02f-805c-40c6-cbf8-5a1d8f0ec86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7fBtNDKxnyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
        "                              name=\"caps2_output_norm\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPCMX0qvxp_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
        "                              name=\"present_error_raw\")\n",
        "present_error = tf.reshape(present_error_raw, shape=(-1, 10),\n",
        "                           name=\"present_error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YTc4i5YxsQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
        "                             name=\"absent_error_raw\")\n",
        "absent_error = tf.reshape(absent_error_raw, shape=(-1, 10),\n",
        "                          name=\"absent_error\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjvnuhYzxulJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
        "           name=\"L\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRl8jjBfxzFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZeN59thESfi",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EvXDzTHZaln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
        "                                               name=\"mask_with_labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Ll6aT6B9me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
        "                                 lambda: y,        # if True\n",
        "                                 lambda: y_pred,   # if False\n",
        "                                 name=\"reconstruction_targets\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THM7yvacCAJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
        "                                 depth=caps2_n_caps,\n",
        "                                 name=\"reconstruction_mask\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6h15GOOCDSV",
        "colab_type": "code",
        "outputId": "16f8aeef-e533-48b4-967e-7cda57a4b602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reconstruction_mask"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'reconstruction_mask:0' shape=(?, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5hEs_koCFaD",
        "colab_type": "code",
        "outputId": "c1ae008d-ea36-4e3c-cedc-686f86921116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_round_2/mul:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IS6jVSVCHWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reconstruction_mask_reshaped = tf.reshape(\n",
        "    reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
        "    name=\"reconstruction_mask_reshaped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BAFsycTCJm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_output_masked = tf.multiply(\n",
        "    caps2_output, reconstruction_mask_reshaped,\n",
        "    name=\"caps2_output_masked\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QwvZpVFCMGs",
        "colab_type": "code",
        "outputId": "74409fcc-3ed4-4203-e9a4-d05602c328a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "caps2_output_masked"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'caps2_output_masked:0' shape=(?, 1, 10, 16, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8M43b6bCOI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input = tf.reshape(caps2_output_masked,\n",
        "                           [-1, caps2_n_caps * caps2_n_dims],\n",
        "                           name=\"decoder_input\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGVBeostCQOP",
        "colab_type": "code",
        "outputId": "2899f65d-b0e5-4144-feb2-b0936282c1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'decoder_input:0' shape=(?, 160) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzJ5KPwnCSPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden1 = 512\n",
        "n_hidden2 = 1024\n",
        "n_output = 28 * 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTcSowQoCUuL",
        "colab_type": "code",
        "outputId": "da0694ba-f5f6-491b-e429-453cecf5042e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "with tf.name_scope(\"decoder\"):\n",
        "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
        "                              activation=tf.nn.relu,\n",
        "                              name=\"hidden1\")\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
        "                              activation=tf.nn.relu,\n",
        "                              name=\"hidden2\")\n",
        "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
        "                                     activation=tf.nn.sigmoid,\n",
        "                                     name=\"decoder_output\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-56-ca7ebd35d3b1>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3IrhDHoCbvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
        "squared_difference = tf.square(X_flat - decoder_output,\n",
        "                               name=\"squared_difference\")\n",
        "reconstruction_loss = tf.reduce_mean(squared_difference,\n",
        "                                    name=\"reconstruction_loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkLnkhcRCf6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.0005\n",
        "\n",
        "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEQFLwis9C7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = tf.equal(y, y_pred, name=\"correct\")\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkdQeIGA9GEp",
        "colab_type": "code",
        "outputId": "fa71adaa-572e-4d94-d1e0-51cf2a10e184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "training_op = optimizer.minimize(loss, name=\"training_op\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H5qTkbS9ITo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7UCA76R5TL",
        "colab_type": "code",
        "outputId": "67e923c7-c304-4cad-fad8-39cc056e38cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdv095rz8Y2X",
        "colab_type": "code",
        "outputId": "3986545e-9dad-40b5-cf25-f6ba5ae3d13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
        "import tensorflow as tf\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7RAu63l8ePm",
        "colab_type": "code",
        "outputId": "4dbef8ae-6602-4b2e-90df-ad147eb6f656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "n_samples = 5\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    sample_image = train_images[index].reshape(28, 28)\n",
        "    plt.imshow(sample_image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXXSqCGD8oRs",
        "colab_type": "code",
        "outputId": "f41e36c8-5763-4311-ae30-e75e02848a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "mnist.train.labels[:n_samples]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 3, 4, 6, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZyXSCQ99LVZ",
        "colab_type": "code",
        "outputId": "07d82ce9-435e-4993-c5d4-36d95180788e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "n_epochs = 5\n",
        "batch_size = 50\n",
        "restore_checkpoint = True\n",
        "\n",
        "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
        "n_iterations_validation = mnist.validation.num_examples // batch_size\n",
        "best_loss_val = np.infty\n",
        "checkpoint_path = \"./my_capsule_network\"\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "    else:\n",
        "        init.run()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            # Run the training operation and measure the loss:\n",
        "            _, loss_train = sess.run(\n",
        "                [training_op, loss],\n",
        "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
        "                           y: y_batch,\n",
        "                           mask_with_labels: True})\n",
        "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
        "                      iteration, n_iterations_per_epoch,\n",
        "                      iteration * 100 / n_iterations_per_epoch,\n",
        "                      loss_train),\n",
        "                  end=\"\")\n",
        "\n",
        "        # At the end of each epoch,\n",
        "        # measure the validation loss and accuracy:\n",
        "        loss_vals = []\n",
        "        acc_vals = []\n",
        "        for iteration in range(1, n_iterations_validation + 1):\n",
        "            X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
        "            loss_val, acc_val = sess.run(\n",
        "                    [loss, accuracy],\n",
        "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
        "                               y: y_batch})\n",
        "            loss_vals.append(loss_val)\n",
        "            acc_vals.append(acc_val)\n",
        "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
        "                      iteration, n_iterations_validation,\n",
        "                      iteration * 100 / n_iterations_validation),\n",
        "                  end=\" \" * 10)\n",
        "        loss_val = np.mean(loss_vals)\n",
        "        acc_val = np.mean(acc_vals)\n",
        "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
        "            epoch + 1, acc_val * 100, loss_val,\n",
        "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
        "\n",
        "        # And save the model if it improved:\n",
        "        if loss_val < best_loss_val:\n",
        "            save_path = saver.save(sess, checkpoint_path)\n",
        "            best_loss_val = loss_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-65-931b8d0cc3fe>:11: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Epoch: 1  Val accuracy: 98.9000%  Loss: 0.013539 (improved)\n",
            "Epoch: 2  Val accuracy: 99.1600%  Loss: 0.010620 (improved)\n",
            "Epoch: 3  Val accuracy: 99.2000%  Loss: 0.009028 (improved)\n",
            "Epoch: 4  Val accuracy: 99.4000%  Loss: 0.007414 (improved)\n",
            "Epoch: 5  Val accuracy: 99.3600%  Loss: 0.007599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n00Vm1vhCmTC",
        "colab_type": "code",
        "outputId": "6419b8c8-f79e-4a50-a6fe-7258246b5ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n_iterations_test = mnist.test.num_examples // batch_size\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, checkpoint_path)\n",
        "\n",
        "    loss_tests = []\n",
        "    acc_tests = []\n",
        "    for iteration in range(1, n_iterations_test + 1):\n",
        "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
        "        loss_test, acc_test = sess.run(\n",
        "                [loss, accuracy],\n",
        "                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
        "                           y: y_batch})\n",
        "        loss_tests.append(loss_test)\n",
        "        acc_tests.append(acc_test)\n",
        "        print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
        "                  iteration, n_iterations_test,\n",
        "                  iteration * 100 / n_iterations_test),\n",
        "              end=\" \" * 10)\n",
        "    loss_test = np.mean(loss_tests)\n",
        "    acc_test = np.mean(acc_tests)\n",
        "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(\n",
        "        acc_test * 100, loss_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n",
            "Final test accuracy: 99.3500%  Loss: 0.007409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG3vCGCeCpRv",
        "colab_type": "code",
        "outputId": "bb671ce2-6f4b-4383-be37-e423ec75401c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_samples = 5\n",
        "\n",
        "sample_images = mnist.test.images[:n_samples].reshape([-1, 28, 28, 1])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, checkpoint_path)\n",
        "    caps2_output_value, decoder_output_value, y_pred_value = sess.run(\n",
        "            [caps2_output, decoder_output, y_pred],\n",
        "            feed_dict={X: sample_images,\n",
        "                       y: np.array([], dtype=np.int64)})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_capsule_network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pDvMWY3CuPo",
        "colab_type": "code",
        "outputId": "dda9c0ec-313b-47db-cdde-372304efeaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "sample_images = sample_images.reshape(-1, 28, 28)\n",
        "reconstructions = decoder_output_value.reshape([-1, 28, 28])\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    plt.imshow(sample_images[index], cmap=\"binary\")\n",
        "    plt.title(\"Label:\" + str(mnist.test.labels[index]))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    plt.title(\"Predicted:\" + str(y_pred_value[index]))\n",
        "    plt.imshow(reconstructions[index], cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "    \n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB+CAYAAAAgAMvUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAB+CAYAAAAgAMvUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUR0WNGUB5_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}